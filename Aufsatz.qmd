---
title: "Was sind Nutzendenanforderungen an KI als Werkzeug zur Detektion von Misinformation auf Social Media? Wie gehen Personen in diesem Kontext mit unterschiedlichen Feedback-Arten um?"
author: 
  - Kaja Bartsch 
  - Zelda Becker
  - Lena Dung  
  - Anna Feldmann
  - Vanessa Obermüller
date: today 
format: 
  html: 
    toc: true
    code_folding: "hide"
  pdf: default
editor: visual
fontsize: 12pt
bibliography: "https://api.citedrive.com/bib/53a4a654-08eb-4d30-aa79-cc45a44d541d/references.bib?x=eyJpZCI6ICI1M2E0YTY1NC0wOGViLTRkMzAtYWE3OS1jYzQ1YTQ0ZDU0MWQiLCAidXNlciI6ICIxMDkzNSIsICJzaWduYXR1cmUiOiAiMzVhM2MyMjU0ODQ4NDBkNDI5NDI0NGFkYzBkMGQzOWNhOGEzYTU4YjQ5YTMzYjM4NGU2YmQ1OWUwOTMzMThlZCJ9"
csl: "apa (1).csl"
---

**GitHub Repository:** https:\\github.com:vanessaobermueller/SMNF2024-Aufsatz-GruppeA2.git **Fuer die Abgabe aktueller GitHub Hash:** f067746

## Code of Conduct

Wir verpflichten uns als Gruppe sorgfältig mit Feedback, unterschiedlichen Perspektiven und Meinungsverschiedenheiten umzugehen, in dem wir in Diskurs treten, einander zuhören und versuchen, gegensätzliche Meinungen zu verstehen. Des Weiteren teilen wir die Aufgaben gleichmäßig unter allen Autoren auf und verpflichten uns, an vereinbarten Terminen teilzunehmen. Durch eine Übersicht der eben genannten zu beachtenden Faktoren, auf die wir alle Zugriff haben, wird es uns möglich sein, auf einen Blick Termine und Aufgabenverteilungen zu sehen. Wir achten auf die Ehrlichkeit, Genauigkeit und Objektivität unserer Arbeit, indem wir verfasste Texte und Ergebnisse untereinander prüfen und uns gegebenenfalls auch Meinung von Dritten einholen, ohne vertrauliche Daten weiterzugeben und erstellen keine Plagiate. Letzteres überprüfen wir regelmäßig mit zuverlässigen Scannern für Plagiate. Wir manipulieren keine Daten. Dort beharren wir wieder auf gegenseitige Kontrolle. Wir werden die Daten schützen und wahren die Vertraulichkeit, indem Daten sicher gespeichert werden und vertrauliche Daten nicht an Dritte weitergegeben werden. Bei einer Nutzung von AI Tools werden wir diese kennzeichnen.

# 1 Einleitung

# 2 Literaturübersicht

In dem wissenschaftlichen Artikel “Fake news detection within online social media using supervised artificial intelligence algorithms” [@ozbay2020], berichten die Autoren davon, dass soziale Medien viele Vorteile, so wie z.B. geringe Kosten, einen einfachen Zugang zu Informationen und die schnelle Ausbreitung dieser, bieten. Daher sind sie zu einer beliebten Variante geworden, um Informationen zu erhalten. Viele Menschen tendieren dazu, eher Soziale Medien als Ressource für Nachrichten zu benutzen, anstatt klassische Nachrichtenquellen. Diese Quellen sind jedoch nicht qualifiziert. Im folgenden haben wir drei weitere Quellen betrachtet, welche sich mit dem Thema der Nutzung von Künstlicher Intelligenz als Detektion von Misinformationen beschäftigen.

Mit dem Anstieg von sozialen Medien als Informationsquelle, häuft sich das Vorkommen von Misinformationen, wobei es vielen User:innen schwer fällt diese zu erkennen, sagt der Artikel “Finding Strategies Against Misinformation in Social Media: A Qualitative Study” [@urakami2022]. Die Hauptprobleme der User:innen sind die Informationsflut, die Unterscheidung von richtigen und falschen Informationen und der negative Einfluss von Misinformationen auf die Emotionen. Es gibt auch einige Muster, die das Verhalten von User:innen repräsentieren, welche auf Misinformation treffen. Entweder werden diese ignoriert, es werden Freunde und Familie gewarnt, die Informationen überprüft und/oder die wichtigsten Informationen hervorgehoben. Generell kann man aber sagen, dass die meisten keine Strategie haben, wie sie mit Misinformationen umgehen oder diese überhaupt entdecken sollen. Eine Hilfe dabei können KI-Tools sein. Diese können die falschen Informationen entweder entfernen oder weniger sichtbar machen. Das Entfernen nimmt dem/der User:in die Kontrolle über das, was er/sie potenziell lesen möchte/kann. Eine andere Möglichkeit wäre, Warnungen an die Informationen zu knüpfen, wobei hier das Problem entsteht, dass man noch mehr Aufmerksamkeit auf die Misinformationen lenkt. Abgesehen davon können KI-Tools aber dabei helfen, dass User:innen schneller die Wahrhaftigkeit und Glaubwürdigkeit von Informationen erkennen und die Fähigkeit entwickeln, Misinformationen herauszufiltern.

Die Vorgehensweisen von Künstlicher Intelligenz sind aber laut dem Review “Fake news, disinformation and misinformation in social media: a review” [@aimeur2023] noch nicht in der Lage, die Probleme von Misinformation auf Social Media zu lösen. Insbesondere, da Beiträge mit Misinformation so gestaltet sind, dass sie der Wahrheit möglichst ähnlich sehen. Aus diesem Grund ist es für KI schwierig, diese ohne eine dritte Partei zu erkennen. Die Probleme können dabei in drei Kategorien geordnet werden: Content-based issues, contextual issues und issues of existing datasets. Hybrid-Techniken können dabei mehrere Probleme gleichzeitig betrachten, werden dadurch allerdings deutlich komplexer, sodass es schwierig werden kann, zu entscheiden, welche Informationen aus welchem Bereich relevant sind. Zu analysieren, wie Quellen und Verbreiter von Fake News über verschiedene Plattformen arbeiten, ist dabei essentiell, um Misinformation zu erkennen.

[@jahanbakhsh2023] untersucht die Kombination von subjektiven Einschätzungen von User:innen und Künstlicher Intelligenz zur Identifikation von Misinformation auf Social Media Plattformen. Die Autoren argumentieren, dass herkömmliche Ansätze zur Bekämpfung von Misinformationen aufgrund der Dynamik der sozialen Medienlandschaft unzureichend sind. Bei dem Ansatz der personalisierten KI interagiert diese mit den Teilnehmer:innen, lernt und analysiert Twitter-Feeds und versucht, eine Beurteilung vorherzusagen, welche an User:innen individuell angepasst ist. Die Diskussion betrachtet sowohl ihr Potential, äußert aber auch Bedenken. Dabei werden zu beachtende ethische Aspekte der Personalisierung und Umsetzungsmöglichkeiten beleuchtet. Des Weiteren werden Personalisierung und Zentralisierung solcher KI-Tools gegenübergestellt und Fragen über das Ausmaß der Transparenz der Entscheidung und Autonomie der User:innen aufgeworfen, sowohl als auch die Fähigkeit der User:innen, Misinformation im Rahmen des Lernprozesses zu erkennen und die Gefahren von Filterblasen. Die Ergebnisse zeigen Fortschritte in dem Gebiet der Bekämpfung von Misinformation, die Autoren betonen jedoch die große Notwendigkeit weiterer Forschung auf diesem Gebiet.

Zusammenfassend sieht man, dass es viele verschiedene Perspektiven zu dem Thema der Nutzung von KI zur Entdeckung von Misinformationen gibt. Zum einen könnten KI-Tools helfen, Misinformationen zu erkennen und gegen diese vorzugehen, jedoch sind diese aktuell oft noch nicht in der Lage diese sicher zu erkennen. Für unser Thema, also die Nutzungsanforderungen an entsprechende KI sind diese Artikel relevant, da sie mögliche Problemstellungen aufzeigen. Im ersten Artikel werden die aktuellen Probleme von Nutzern und der Erkennung von Misinformationen thematisiert, was wichtig ist, um diese Probleme beim Einsatz von KI vermeiden zu können. Damit die KI glaubwürdig auf die Nutzer wirkt, muss sie die Informationen richtig einstufen. Mit den Problemen die dabei entstehen, beschäftigt sich der zweite Artikel. Auch die Personalisierung ist ein wichtiges Thema, damit Nutzer gerne mit einem System arbeiten, welches der dritte Artikel aufgreift und problematisiert, wie mit Transparenz und Autonomie ethisch korrekt umgegangen werden kann.

# 3 Methodik

## 3.1 Qualitative Methode
Um qualitative Daten zu erheben, haben wir in einem Zeitraum von zwei Wochen (14.05.24 – 28.05.24) leitfadengestütze bzw. semistrukturierte Interviews (A1) geführt. Dabei haben die Befragten Fragen zu KIs, Social Media und Misinformationen beantwortet. Zuerst wurden die Befragten über den Verlauf des Interviews aufgeklärt. Anschließend kam der Einstieg ins Thema und die ersten Fragen zu den bisherigen Erfahrungen mit KIs und über die Nutzung von Social Media. Außerdem, welche Erfahrungen schon mit Misinformationen (im Zusammenhang mit Social Media) gemacht wurden. Im Hauptteil wurde ermittelt, welche Nutzungsanforderungen die Nutzenden an ein KI-Tool hätten. Dabei wurde zuerst erfragt, ob so ein System überhaupt helfen würde und dann, welche Eigenschaften (automatische Anzeige der Informationen, Interaktion, welche Informationen werden gezeigt) es haben sollte. Schließlich gab es noch Fragen zur Verantwortung und Transparenz des KI-Tools, bevor das Interview nach Zusammenfassung beendet wurde.
Das einzige Einschlusskriterium, um beim Interview teilnehmen zu können, war, gute Deutschkenntisse zu haben, da das Interview auf Deutsch geführt wurde. Mehr Kriterien waren für uns nicht nötig, da uns die Meinung zu dem KI-Tool unabhängig zu Vorerfahrungen, Technikaffinität oder anderen Faktoren interessiert. Andere demografische Einschränkungen waren deswegen auch nicht relevant. Da heutzutage auch (fast) jede Person im Internet unterwegs ist und (sehr wahrscheinlich) in Kontakt mit Misinformationen gerät, waren keine weiteren Ausschlusskriterien nötig.
Um die erhobenen Daten zu analysieren, haben wir das Verfahren der Thematischen Analyse angewendet. Wir haben also aus jedem Interview die für die Forschungsfrage relevanten Inhalte und Informationen herausgefiltert und in Themen kategorisiert, um so die Nutzungsanforderungen an das KI-Tool bestimmen zu können. Die dabei entstandenen Codes sind: Erfahrungen, Eigenschaften, Misinformationen, Verantwortung und Transparenz. Und aus diesen sind dann folgende Themen entstanden: Misinformationen auf Social Media, Eigenschaften des KI-Tools, Grenzen und Sorgen, Verantwortung für das KI-Tool und Transparenz des KI-Tools.
A1: Leitfaden zum Interview 

Diagramm zur Veranschaulichung des Studienablaufs:

## 3.2 Quantitative Methode 
Ablauf der Datenerhebung

Die Datenerhebung für die quantitative Methode fand vom Dienstag, den 28. Mai, bis zum Montag, den 10. Juni, statt. Die Teilnehmenden wurden über die Umfrage informiert und erhielten einen Link zur Umfrage, die sie selbstständig innerhalb dieses zweiwöchigen Zeitraums durchführen konnten. Das Studiendesign unserer Forschung ist eine Fragebogenstudie mit einer Dauer von 30 Minuten, die durch die Verwendung von Skalen unterstützt wird. Die Studie gliedert sich in drei Abschnitte. Im ersten Abschnitt werden Fragen zur Person der Teilnehmenden gestellt, um demografische und persönliche Informationen zu erfassen. Im zweiten Abschnitt testen die Teilnehmenden die Anwendung, indem ihnen eine Auswahl an fiktiven Social-Media-Posts angezeigt wird. Dabei sollen sie mithilfe der Anwendung bewerten, ob es sich bei den Posts um falsche oder irreführende Informationen handelt. Im abschließenden dritten Abschnitt beantworten die Teilnehmenden Fragen zu ihrer Einschätzung und Bewertung der Anwendung, um deren Feedback und Erfahrungen zu erfassen. 

Das nachfolgende Diagramm veranschaulicht den Ablauf der Onlineumfrage:

Beschreibung der Teilnehmenden 

Insgesamt nahmen 15 Personen an unserer Studie teil und durchliefen erfolgreich alle Abschnitte der Onlineumfrage. Die Auswahl der Teilnehmenden erfolgte anhand bestimmter Einschluss- und Ausschlusskriterien. Die Kriterien für die Teilnahme an unserer Onlineumfrage sind wie folgt: Die Teilnehmenden müssen volljährig sein, über gute Deutschkenntnisse verfügen, grundlegende Erfahrungen im Umgang mit Online-Umfragen haben und der Verarbeitung ihrer Daten zustimmen.
Wir haben uns für die Altersgruppe zwischen 18 und 70 Jahren entschieden, um eine vielseitige Perspektive zu gewährleisten. Die Nutzung von Social Media ist nicht auf eine bestimmte Altersgruppe beschränkt, sondern wird von Menschen unterschiedlichen Alters und mit verschiedenen Hintergründen genutzt. Indem wir Teilnehmende aus einer breiten Altersspanne einbeziehen, können wir umfassendere und repräsentativere Ergebnisse erzielen, die die vielfältigen Erfahrungen und Sichtweisen der Nutzer widerspiegeln.
Gute Deutschkenntnisse sind ein weiteres Kriterium für die Teilnahme. Da die Umfrage und die verwendeten Skalen in deutscher Sprache verfasst sind, ist es entscheidend, dass die Teilnehmenden über ausreichende Sprachkenntnisse verfügen, um die Fragen korrekt zu verstehen und präzise zu beantworten. Dies stellt sicher, dass die erhobenen Daten valide und zuverlässig sind.
Ein grundlegendes Verständnis für Online-Umfragen ist ebenfalls notwendig, um sicherzustellen, dass die Teilnehmenden die Umfrage ohne Schwierigkeiten durchführen können. Dies minimiert das Risiko von Abbrüchen und technischen Problemen und trägt zur Qualität und Vollständigkeit der erhobenen Daten bei. 
Die Zustimmung zur Verarbeitung ihrer Daten ist ein essenzielles Kriterium, um die ethischen und rechtlichen Standards der Forschung einzuhalten. Die Einwilligung stellt sicher, dass die Teilnehmenden über die Verwendung ihrer Daten informiert sind und dieser zustimmen. Dies fördert das Vertrauen der Teilnehmenden und schützt ihre Rechte und Privatsphäre.

Gewählte Methoden 

Die gewählte Methode für die Onlineumfrage ist die Verwendung von Skalen. Dabei werden verschiedene Skalenniveaus angewendet, um unterschiedliche Arten von Daten zu erfassen.
Nominale Daten lassen sich nicht in eine Rangfolge bringen. Dies bedeutet, dass wir nicht sagen können, ob ein Wert besser oder schlechter als ein anderer ist, sondern lediglich, ob es einen Unterschied gibt. Nominale Daten geben uns Informationen über die Häufigkeit bestimmter Merkmale. In unserer Umfrage wird das nominale Skalenniveau für das Geschlecht der Teilnehmenden verwendet, wobei die Kategorien "Männlich" und "Weiblich" erfasst werden.
Ordinalskalierte Daten können wir in eine Rangfolge bringen, jedoch können wir keine genauen Aussagen über die Abstände zwischen den Werten machen. Wir können feststellen, welche Werte höher oder niedriger sind, aber nicht, wie viel höher oder niedriger sie sind. Ordinale Daten geben uns Informationen über die Häufigkeit und die Rangfolge bestimmter Merkmale. In unserer Umfrage werden der höchste allgemeinbildenden Schulabschluss und der höchste berufliche Abschluss auf ordinaler Basis erfasst, da sie eine Reihenfolge haben, aber keine genauen Abstände zwischen den Abschlüssen angegeben sind. Für den schulischen Abschluss stehen folgende Optionen zur Auswahl: "(noch) keinen Abschluss", "Hauptschulabschluss", "Realschulabschluss", "Abitur". Für den beruflichen Abschluss stehen folgende Optionen zur Auswahl: "(noch) keinen Abschluss", "Lehre/Ausbildung", "Fachschule", "Universität/Hochschule".
Für metrische Daten können wir eine Rangfolge erstellen und die Abstände zwischen den Werten sind klar definiert. Metrische Daten ermöglichen uns, sowohl die Häufigkeit als auch die Rangfolge und den genauen Abstand zwischen den Werten zu bestimmen
Im Pre-test-Fragebogen und in beiden Post-test Fragebögen erfolgt die Abfrage mithilfe eines metrischen Skalenniveaus und einer sechsstufigen Likert-Skala. Die Teilnehmenden werden gebeten, ihre Zustimmung zu Aussagen auf einer Skala von "Stimmt gar nicht" über "Stimmt weitgehend nicht" und "Stimmt eher nicht" bis "Stimmt eher", "Stimmt weitgehend" und schließlich "Stimmt völlig" einzuschätzen. Die Likert-Skala ermöglicht eine differenzierte Bewertung, indem sie den Grad der Übereinstimmung oder Ablehnung mit den Aussagen bestimmt.

Analysemethode 

Ausgewählte Variablen für unsere Onlineumfrage sind folgende.
Variablen für den Pre-test Fragebogen sind Soziodemographische Daten wie Alter, Geschlecht, Bildungsgrad. Ebenfalls Daten zu der Persönlichkeit der Teilnehmenden, die Einstellung zu Technik, zu den Nutzungsgewohnheiten in den sozialen Medien und zu der Vorerfahrung mit KI. Variablen für die System-Evaluation sind Erfolg, Anzahl der Interaktionen und Time-on-Task. Diese Daten dienen der Bewertung der Posts und fassen die Interaktion mit der Anwendung zusammen. Die Variablen für die Post-test Fragebogen sind Usability, User Experience, Subjektives Bewusstsein für die Informationsverarbeitung und Vertrauen in das System. Dies sind Daten zu der Bewertung der Anwendung. 
Nach der Auswertung der Onlineumfragen werden quantitative Analysemethoden verwendet, darunter statistische Verfahren wie t-Test und Korrelation. Diese Methoden dienen der Untersuchung von den ausgewählten Variablen, um fundierte Erkenntnisse aus den Umfragedaten zu gewinnen. 
Der t-Test stellt fest, ob es einen signifikanten Unterschied zwischen den Mittelwerten von zwei Gruppen gibt. Die Korrelation hingegen misst den Zusammenhang zwischen zwei Variablen und zeigt, in welchem Ausmaß sich Veränderungen einer Variable auf die andere Variable auswirkt. Beide Methoden werden somit verwendet, um Beziehungen und Muster in den Daten rauszufiltern und zu analysieren. Somit können Hypothesen bestätigt oder widerlegt werden und dadurch können Entscheidungen über den weiteren Verlauf der Studie getroffen werden.


# 4 Ergebnisse



```{r code, echo = FALSE}
ati <- read.csv("mturk_data.csv", header = TRUE ,)
mean_age <- mean(ati$age)
mean_ati_young <- mean(ati[ati$age < mean_age,"ati_mean"])

mean_ati_old <- mean(ati[ati$age >= mean_age, "ati_mean"]) 

```

Jüngere Teilnehmer haben im Schnitt einen leicht höheren ATI Score von `r round(mean_ati_young,2)` als ältere Teilnehmer, welche einen ATI Score von `r round(mean_ati_old,2)` haben. Daraus folgt, dass beide Gruppen ein ähnlich hohes Ausmaß an Technikaffinität aufzeigen.


## 4.1 Qualitative Ergebnisse
Aus der thematischen Analyse der Transkripte ergeben sich folgende Themen, die relevant für unsere Forschungsfrage sind: Misinformationen, Eigenschaften, Grenzen, Verantwortung und Transparenz.

| Name  | Definition | Beleg |
|------|------|------|
| Misinformationen auf Social Media | Notwendigkeit eines KI-Tools, das Informationen im Internet beurteilt und dessen Nützlichkeit    | „Ehm, gerade auf Seiten wie Instagram und Tiktok, wo jeder posten kann was er will, muss man vorsichtig sein und darf nicht alles glauben, was einem präsentiert wird, da viele mit oder ohne Absicht andere beeinflussen, indem sie ihre Meinung verbreiten, weil diese von vielen sofort als Wahrheit angenommen wird.“ (A2_5, Zeile 45-49) „Ein ausreichend trainiertes KI System kann natürlich dabei helfen, schnell und ohne menschliches Eingreifen Misinformationen zu spotten und als solche zu flaggen, was es natürlich auch dem endgültigen User einfacher macht, Desinformation von tatsächlichen Fakten zu unterscheiden.“ (A2_4, Zeile 67-71)  |
| Eigenschaften des KI-Tools    | Anforderungen an das KI-Tool, damit es zufriedenstellend und zielführend benutzbar ist    | „Es muss natürlich korrekt sein, also es muss ja schon auf jeden Fall richtig funktionieren.“ (A2_3, Zeile 45-46) „Okay, also ich sprach ja von einem Label und ich stelle mir da so einen Popup-Button vor, dass man da unten in der Mitte vom Screen zum Beispiel sieht man einen Popup-Button, da steht ‚Hierbei handelt es sich wahrscheinlich um Misinformation‘, dann klicken wir da drauf und wunderbar wäre es natürlich, wenn thematisch das aufgegriffen wird, wobei es sich um Misinformation handle und das versucht wird mit Fakten zu unterstützen.“ (A2_1, Zeile 104-110) |
| Grenzen und Sorgen    | Grad, bis zu dem so ein System wirklich helfen und funktionieren kann    | Es kam die Frage auf, ob die Kennzeichnung von Fake News tatsächlich dabei helfen würde, Bewusstsein zu schaffen oder ob die Fronten doch nur verhärtet würden. (vgl. A2_3, Zeile 142-145) „Und deshalb denke ich, dass noch viel daran gearbeitet werden muss, dass so was halt wirklich ernst genommen werden kann, weil KI halt noch nicht alles versteht und deshalb auch oft falsche Antworten liefert.“ (A2_2, Zeile 95-98) | 
|Verantwortung für das KI-Tool | Partie, die sich um Durchführung kümmert | „Irgendein Medium, dass keinen Vorteil hat, wenn Misinfromationen verbreitet werden, also neutral dem gegenübersteht.“ (A2_5, Zeile 97-98) „Ich denke die Verantwortung hat a uf jeden Fall die Social Media Seite.“ (A2_4, Zeile 150-151) |
| Transparenz des KI-Tools | Beurteilungen des KI-Tools nachvollziehen können | „Bei einem transparenten KI-Tool ist es wichtig, welche Daten verwendet werden, um das neutrale Netz zu trainieren und welche Quellen die KI als seriöse Quellen wertet.“ (A2_5, Zeile 105-107) „Ich finde es sollte Optionen geben, vielleicht könnte es einfach die Informationen sozusagen liefern und dann auch noch Optionen geben, dass man sozusagen den Gedankengang, also auch wenn KIs keinen Gedankengang haben, aber den Gedankengang dahinter noch mal, um den nachvollziehen zu können.“ (A2_3, Zeile 104-108) |

Bei dem Thema „Misinformationen auf Social Media“ geht es darum, ob die Befragten ein KI-Tool dieser Art überhaupt als notwendig erachten. Alle Befragten haben angegeben, schon mal in Kontakt mit Misinformationen geraten zu sein. Außerdem wäre so ein System laut ihnen hilfreich und könne bis zu einem gewissen Grad definitiv dabei helfen, das Problem von Verbreitung von Misinformationen anzugehen.
Wie man das System gestalten sollte, dass es den Anforderungen der Nutzenden entspricht, wird mit dem Thema „Eigenschaften des KI-Tools“ beschrieben. Höchste Priorität hatte bei den Befragten die Zuverlässigkeit des Systems. Es muss neutrale, faktenbasierte Entscheidungen treffen können und mit seriösen Quellen arbeiten. Am wichtigsten sei es, dass das System keine richtigen Informationen als falsch markiert und dass es sowohl Bild, Video, Audio und Text prüft, um ein bestmögliches Ergebnis zu liefern. Wenn es um die direkte Nutzung geht, hatten mehrere Befragte die Vorstellung, dass die entsprechenden Posts mit einer Art Icon versehen werden, sodass man weiß, dass dieser Post Misinformationen enthält. Klickt man auf das Icon, wäre es optimal, wenn man noch mehr Informationen zu dem Thema bekommt oder die Option hat, sich selbst noch weiter zu informieren. Dieses Icon soll auch immer zu sehen sein und nicht erst auf Anfrage. Außerdem soll man die KI-Response melden können, im Falle einer falschen Markierung, aber mehr Interaktion muss mit dem System nicht möglich sein. Eine andere Idee für so ein System ist, dass man selbst Informationen in das System gibt und diese von der KI prüfen lässt und nicht, dass die KI automatisch immer alle Posts prüft. 
Es wurden auch einige kritische Gedanken geäußert, die im Thema „Grenzen und Sorgen“ festgehalten sind. Zum einen wurde hinterfragt, ob eine KI subjektive Meinungen, Satire und Sarkasmus erkennen und beurteilen kann. Außerdem wurde mehrfach geäußert, dass die KI auf jeden Fall „neutral“, „unparteiisch“ oder „unbiased“ entscheiden müsse und ob es generell überhaupt möglich sei, eine KI mit solchen Anforderungen zu entwickeln.
Zum Thema „Verantwortung für das KI-Tool“ wäre die optimale Lösung, dass es eine dritte, unabhängige Partei gäbe, die keinen Nutzen von Verbreitung oder Verbergung von Informationen hat. Da dies aber unrealistisch erscheint, läge die Verantwortung wohl bei den Social Media Seiten, wobei auch der Gedanke geäußert wurde, dass es Richtlinien vom Staat geben soll, an die sich die Social Media Seiten halten müssen. 
Als letztes geht es noch um das Thema „Transparenz des KI-Tools“. Man soll auf jeden Fall die Entscheidungen bzw. Beurteilungen der KI einsehen und nachvollziehen können und die Quellen, auf die sich die KI bezieht, überprüfen können. Außerdem seien Quelloffenheit des Codes und Transparenz im Datensatz, mit der die KI trainiert wird, wichtig.

## 4.2 Quantitative Ergebnisse 
@fig-codeati stellt den Zusammenhang zwischen ATI-1 und ATI-2 dar. 

```{r}
#| echo: false
#| message: false
#| fig-cap: "Zusammenhang zwischen ATI-1 und ATI-2"
#| label: fig-codeati

library(ggplot2)
library(tidyverse)

daten <- read.csv("mturk_data.csv")
ggplot(daten, aes(x = ati01, y = ati02)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, fullrange = TRUE)+
  scale_x_continuous(limits = c(1,6), breaks = seq(1,6,1)) +
  scale_y_continuous(limits = c(1,6), breaks = seq(1,6,1))  
 
  
```


# 5 Diskussion

# 6 Literaturverzeichnis
<div id = "refs" ></div>

# 7 Anhänge
## Anhang 1 - Rekrutierungstext

Hallo zusammen!

Falschinformationen sind weit verbreitet und jeder ist mit Ihnen tagtäglich konfrontiert.\
In unserer Fragenbogenstudie testest du ein KI Werkzeugs (Künstliche Intelligenz), welches dir hilft irreführende Informationen im Internet zu erkennen.\
Die Studie dauert ca. 30 - 45 Minuten und kann einfach vom Laptop / Tablet / PC online durchgeführt werden.\
Medieninformatik- und Psychologie-Studierende der Universität Lübeck erhalten für die Teilnahme 0,5 VP Stunden.\ 

Unsere Einschlusskriterien sind

-	Mindestens 18 Jahre alt 

-	Gute Deutschkenntnisse

Der Link zur Teilnahme: insert Link lol\
Wir freuen uns auf deine Teilnahme!
