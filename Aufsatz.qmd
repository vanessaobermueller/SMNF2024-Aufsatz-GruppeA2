---
title: "Misinformation auf Social Media: Die Notwendigkeit zur Detektion"
author: 
  - Kaja Bartsch 
  - Zelda Becker
  - Lena Dung  
  - Anna Feldmann
  - Vanessa Obermüller
date: today 
format: 
  html: 
    toc: true
    code_folding: "hide"
  pdf: default
editor: visual
fontsize: 12pt
bibliography: "https://api.citedrive.com/bib/53a4a654-08eb-4d30-aa79-cc45a44d541d/references.bib?x=eyJpZCI6ICI1M2E0YTY1NC0wOGViLTRkMzAtYWE3OS1jYzQ1YTQ0ZDU0MWQiLCAidXNlciI6ICIxMDkzNSIsICJzaWduYXR1cmUiOiAiMzVhM2MyMjU0ODQ4NDBkNDI5NDI0NGFkYzBkMGQzOWNhOGEzYTU4YjQ5YTMzYjM4NGU2YmQ1OWUwOTMzMThlZCJ9"
---

**GitHub Repository:** https://github.com/vanessaobermueller/SMNF2024-Aufsatz-GruppeA2.git **Fuer die Abgabe aktueller GitHub Hash:** e722c81

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Code of Conduct

Wir verpflichten uns als Gruppe sorgfältig mit Feedback, unterschiedlichen Perspektiven und Meinungsverschiedenheiten umzugehen, in dem wir in Diskurs treten, einander zuhören und versuchen, gegensätzliche Meinungen zu verstehen. Des Weiteren teilen wir die Aufgaben gleichmäßig unter allen Autoren auf und verpflichten uns, an vereinbarten Terminen teilzunehmen. Durch eine Übersicht der eben genannten zu beachtenden Faktoren, auf die wir alle Zugriff haben, wird es uns möglich sein, auf einen Blick Termine und Aufgabenverteilungen zu sehen. Wir achten auf die Ehrlichkeit, Genauigkeit und Objektivität unserer Arbeit, indem wir verfasste Texte und Ergebnisse untereinander prüfen und uns gegebenenfalls auch Meinung von Dritten einholen, ohne vertrauliche Daten weiterzugeben und erstellen keine Plagiate. Letzteres überprüfen wir regelmäßig mit zuverlässigen Scannern für Plagiate. Wir manipulieren keine Daten. Dort beharren wir wieder auf gegenseitige Kontrolle. Wir werden die Daten schützen und wahren die Vertraulichkeit, indem Daten sicher gespeichert werden und vertrauliche Daten nicht an Dritte weitergegeben werden. Bei einer Nutzung von AI Tools werden wir diese kennzeichnen.

# 1 Einleitung

Social Media ist in der heutigen Zeit ein essenzieller Bestandteil unserer Gesellschaft. Dabei dient es immer weniger nur der reinen Unterhaltung. Informationsbeschaffung und Informationsverbreitung über das Netz sind ebenso alltäglich geworden, wie das Scrollen zum Zeitvertreib. Doch können nicht nur offizielle Seiten diese Informationen bereitstellen. Den UserInnen selbst ist es auch möglich, die Informationen hochzuladen, die andere dann konsumieren. Dies führt dazu, dass inzwischen Unmengen an Meinungen, Neuigkeiten und Fakten im Internet kursieren – nur kann man sich nie über den Wahrheitsgehalt dieser Informationen auf Social Media sicher sein.

Den meisten UserInnen ist die Menge an Misinformationen, die sie täglich lesen, gar nicht bewusst. Dabei kann im schlimmsten Fall durch gezielte Misinformationskampagnen, Misstrauen in der Gesellschaft geweckt werden, was begünstigend für z.B. Verschwörungstheorien ist und das Vertrauen in die Medien und Institutionen zerstören kann. Es werden Fakten erfunden, aus dem Kontext gerissen oder unvollständig dargestellt. Umso wichtiger ist es also, dass einem bewusst wird, wie man diese Misinformationen erkennen kann. Und außerdem, dass man das Feld von Misinformationen auf Social Media erforscht, um optimal dagegen vorgehen zu können.

Es bleibt bislang aber unklar, was der optimale Weg ist, um die UserInnen dabei zu unterstützen, ihren Umgang auf Social Media so reflektiert wie möglich zu gestalten. Es gibt schon einige KI-Tools, die dabei helfen sollen, Misinformationen zu entdecken. Da diese aber häufig noch unglaubwürdig sind oder die UserInnen nicht überzeugen, bedarf es weiterer Forschung rund um KI-Tools und KI-Systeme auf Social Media. Deswegen haben wir uns in dieser Studie mit der Frage beschäftigt, welche Nutzendenanforderungen es an KI als Werkzeug zur Detektion von Misinformation auf Social Media gibt und wie Personen in diesem Kontext mit unterschiedlichen Feedback-Arten umgehen.

Da heutzutage auch alle Altersgruppen auf Social Media vertreten sind, ist es wichtig, das KI-Tool so zu konzipieren, dass keine Altersgruppe Probleme mit dessen Nutzung hat. Genauer stellen wir uns also die Frage, ob das Alter eines Menschen ein entscheidender Faktor bei der Konzipierung von KI-Tools zur Detektion von Misinformationen ist und ob es in Hinblick dessen Zusammenhänge zwischen dem Alter und unter anderem der Usability oder dem Vertrauen gegenüber solcher KI-Tools gibt. Damit stellt sich auch die Frage, wie dynamisch und/oder individuell solche KI-Tools aufgebaut sein müssen, damit diese über Altersgrenzen hinweg funktionieren und verstanden werden.

# 2 Literaturübersicht

In dem wissenschaftlichen Artikel “Fake news detection within online social media using supervised artificial intelligence algorithms” [@ozbay2020], berichten die Autoren davon, dass Social Media viele Vorteile, so wie z.B. geringe Kosten, einen einfachen Zugang zu Informationen und die schnelle Ausbreitung dieser, bieten. Daher sind sie zu einer beliebten Variante geworden, um Informationen zu erhalten. Viele Menschen tendieren dazu, eher Social Media als Ressource für Nachrichten zu benutzen, anstatt klassische Nachrichtenquellen. Diese Quellen sind jedoch nicht qualifiziert.

Mit dem Anstieg von Social Media als Informationsquelle häuft sich das Vorkommen von Misinformationen, wobei es vielen UserInnen schwer fällt diese zu erkennen. Dies untersucht der Artikel “Finding Strategies Against Misinformation in Social Media: A Qualitative Study” [@urakami2022]. Die Hauptprobleme der UserInnen sind die Informationsflut, die Unterscheidung von richtigen und falschen Informationen und der negative Einfluss von Misinformationen auf die Emotionen. Es gibt auch einige Muster, die das Verhalten von UserInnen repräsentieren, welche auf Misinformation treffen. Entweder werden diese ignoriert, es werden Freunde und Familie gewarnt, die Informationen überprüft und/oder die wichtigsten Informationen hervorgehoben. Generell kann man aber sagen, dass die meisten keine Strategie haben, wie sie mit Misinformationen umgehen oder diese überhaupt entdecken sollen. Eine Hilfe dabei können KI-Tools sein. Diese können die falschen Informationen entweder entfernen oder weniger sichtbar machen. Das Entfernen nimmt dem/der UserIn die Kontrolle über das, was er/sie potenziell lesen möchte/kann. Eine andere Möglichkeit wäre, Warnungen an die Informationen zu knüpfen, wobei hier das Problem entsteht, dass man noch mehr Aufmerksamkeit auf die Misinformationen lenkt. Abgesehen davon können KI-Tools aber dabei helfen, dass UserInnen schneller die Wahrhaftigkeit und Glaubwürdigkeit von Informationen erkennen und die Fähigkeit entwickeln, Misinformationen herauszufiltern.

Die Vorgehensweisen von Künstlicher Intelligenz sind aber laut dem Review “Fake news, disinformation and misinformation in social media: a review” [@aimeur2023] noch nicht in der Lage, die Probleme von Misinformation auf Social Media zu lösen. Insbesondere, da Beiträge mit Misinformation so gestaltet sind, dass sie der Wahrheit möglichst ähnlich sehen. Aus diesem Grund ist es für KI schwierig, diese ohne eine dritte Partei zu erkennen. Die Probleme können dabei in drei Kategorien geordnet werden: Content-based issues, contextual issues und issues of existing datasets. Hybrid-Techniken können dabei mehrere Probleme gleichzeitig betrachten, werden dadurch allerdings deutlich komplexer, sodass es schwierig werden kann, zu entscheiden, welche Informationen aus welchem Bereich relevant sind. Zu analysieren, wie Quellen und Verbreiter von Fake News über verschiedene Plattformen arbeiten, ist dabei essentiell, um Misinformation zu erkennen.

[@jahanbakhsh2023] untersucht die Kombination von subjektiven Einschätzungen von UserInnen und Künstlicher Intelligenz zur Identifikation von Misinformation auf Social Media Plattformen. Die Autoren argumentieren, dass herkömmliche Ansätze zur Bekämpfung von Misinformationen aufgrund der Dynamik der sozialen Medienlandschaft unzureichend sind. Bei dem Ansatz der personalisierten KI interagiert diese mit den TeilnehmerInnen, lernt und analysiert Twitter-Feeds und versucht, eine Beurteilung vorherzusagen, welche an UserInnen individuell angepasst ist. Die Diskussion betrachtet sowohl ihr Potential, äußert aber auch Bedenken. Dabei werden zu beachtende ethische Aspekte der Personalisierung und Umsetzungsmöglichkeiten beleuchtet. Des Weiteren werden Personalisierung und Zentralisierung solcher KI-Tools gegenübergestellt und Fragen über das Ausmaß der Transparenz der Entscheidung und Autonomie der UserInnen aufgeworfen, sowohl als auch die Fähigkeit der UserInnen, Misinformation im Rahmen des Lernprozesses zu erkennen und die Gefahren von Filterblasen. Die Ergebnisse zeigen Fortschritte in dem Gebiet der Bekämpfung von Misinformation, die AutorInnen betonen jedoch die große Notwendigkeit weiterer Forschung auf diesem Gebiet.

Zusammenfassend sieht man, dass es viele verschiedene Perspektiven zu dem Thema der Nutzung von KI zur Entdeckung von Misinformationen gibt. Zum einen könnten KI-Tools helfen, Misinformationen zu erkennen und gegen diese vorzugehen, jedoch sind diese aktuell oft noch nicht in der Lage diese sicher zu erkennen. Für unser Thema, also die Nutzungsanforderungen an entsprechende KI, sind diese Artikel relevant, da sie mögliche Problemstellungen aufzeigen. Im ersten Artikel werden die aktuellen Probleme von Nutzenden und der Erkennung von Misinformationen thematisiert, was wichtig ist, um diese Probleme beim Einsatz von KI vermeiden zu können. Damit die KI glaubwürdig auf die Nutzenden wirkt, muss sie die Informationen richtig einstufen. Mit den Problemen die dabei entstehen, beschäftigt sich der zweite Artikel. Auch die Personalisierung ist ein wichtiges Thema, damit Nutzende gerne mit einem System arbeiten, welches der dritte Artikel aufgreift und problematisiert, wie mit Transparenz und Autonomie ethisch korrekt umgegangen werden kann.

# 3 Methodik

## 3.1 Qualitative Methode

Um qualitative Daten zu erheben, haben wir in einem Zeitraum von zwei Wochen (14.05.24 – 28.05.24) leitfadengestütze bzw. semistrukturierte Interviews (A1) geführt. Dabei haben die Befragten Fragen zu KIs, Social Media und Misinformationen beantwortet. Zuerst wurden die Befragten über den Verlauf des Interviews aufgeklärt. Anschließend kam der Einstieg ins Thema und die ersten Fragen zu den bisherigen Erfahrungen mit KIs und über die Nutzung von Social Media. Außerdem wurden Informationen darüber gesammelt, welche Erfahrungen schon mit Misinformationen (im Zusammenhang mit Social Media) gemacht wurden.

Im Hauptteil wurde ermittelt, welche Nutzungsanforderungen die Nutzenden an ein KI-Tool hätten. Dabei wurde zuerst erfragt, ob so ein System überhaupt helfen würde und dann, welche Eigenschaften (automatische Anzeige der Informationen, Interaktion, welche Informationen werden gezeigt) es haben sollte. Schließlich gab es noch Fragen zur Verantwortung und Transparenz des KI-Tools, bevor das Interview nach Zusammenfassung beendet wurde. Die einzigen Einschlusskriterien, um beim Interview teilnehmen zu können, waren, gute Deutschkenntisse zu haben, da das Interview auf Deutsch geführt wurde und Volljährigkeit. Mehr Kriterien waren für uns nicht nötig, da uns die Meinung zu dem KI-Tool unabhängig zu Vorerfahrungen, Technikaffinität oder anderen Faktoren interessiert. Andere demografische Einschränkungen waren deswegen auch nicht relevant. Da heutzutage auch (fast) jede Person im Internet unterwegs ist und (sehr wahrscheinlich) in Kontakt mit Misinformationen gerät, waren keine weiteren Ausschlusskriterien nötig.

Um die erhobenen Daten zu analysieren, haben wir das Verfahren der Thematischen Analyse angewendet. Wir haben also aus jedem Interview die für die Forschungsfrage relevanten Inhalte und Informationen herausgefiltert und in Themen kategorisiert, um so die Nutzungsanforderungen an das KI-Tool bestimmen zu können. Die dabei entstandenen Codes sind: Erfahrungen, Eigenschaften, Misinformationen, Verantwortung und Transparenz. Und aus diesen sind dann folgende Themen entstanden: Misinformationen auf Social Media, Eigenschaften des KI-Tools, Grenzen und Sorgen, Verantwortung für das KI-Tool und Transparenz des KI-Tools.

A1: Leitfaden zum Interview

![Diagramm zur Veranschaulichung des Studienablaufs](Qualitativ_Methodenteil_Diagramm.png)

## 3.2 Quantitative Methode

### 3.2.1 Ablauf der Datenerhebung

Die Datenerhebung für die quantitative Methode fand vom Dienstag, den 28. Mai, bis zum Montag, den 10. Juni, statt. Die Teilnehmenden wurden über die Umfrage informiert und erhielten einen Link zur Umfrage, die sie selbstständig innerhalb dieses zweiwöchigen Zeitraums durchführen konnten. Das Studiendesign unserer Forschung ist eine Fragebogenstudie mit einer Dauer von 30 Minuten, die durch die Verwendung von Skalen unterstützt wird. Die Studie gliedert sich in drei Abschnitte.

![Diagramm zur Veranschaulichungden des Ablaufs der Onlineumfrage](Quantitativ_Methodenteil_Diagramm.png)

Im ersten Abschnitt werden Fragen zur Person der Teilnehmenden gestellt, um demografische und persönliche Informationen zu erfassen. Im zweiten Abschnitt testen die Teilnehmenden die Anwendung, indem ihnen eine Auswahl an fiktiven Social-Media-Posts angezeigt wird. Dabei sollen sie mithilfe der Anwendung bewerten, ob es sich bei den Posts um falsche oder irreführende Informationen handelt. Im abschließenden dritten Abschnitt beantworten die Teilnehmenden Fragen zu ihrer Einschätzung und Bewertung der Anwendung, um deren Feedback und Erfahrungen zu erfassen.

### 3.2.2 Beschreibung der Teilnehmenden

Insgesamt nahmen 15 Personen an unserer Studie teil und durchliefen erfolgreich alle Abschnitte der Onlineumfrage. Die Auswahl der Teilnehmenden erfolgte anhand bestimmter Einschluss- und Ausschlusskriterien. Die Kriterien für die Teilnahme an unserer Onlineumfrage sind wie folgt: Die Teilnehmenden müssen volljährig sein, über gute Deutschkenntnisse verfügen, grundlegende Erfahrungen im Umgang mit Online-Umfragen haben und der Verarbeitung ihrer Daten zustimmen. Wir haben uns für die Altersgruppe zwischen 18 und 70 Jahren entschieden, um eine vielseitige Perspektive zu gewährleisten. Die Nutzung von Social Media ist nicht auf eine bestimmte Altersgruppe beschränkt, sondern wird von Menschen unterschiedlichen Alters und mit verschiedenen Hintergründen genutzt.
Indem wir Teilnehmende aus einer breiten Altersspanne einbeziehen, können wir umfassendere und repräsentativere Ergebnisse erzielen, die die vielfältigen Erfahrungen und Sichtweisen der Nutzer widerspiegeln. Da die Umfrage und die verwendeten Skalen in deutscher Sprache verfasst sind, ist es entscheidend, dass die Teilnehmenden über ausreichende Sprachkenntnisse verfügen, um die Fragen korrekt zu verstehen und präzise zu beantworten. Dies stellt sicher, dass die erhobenen Daten valide und zuverlässig sind. Ein grundlegendes Verständnis für Online-Umfragen ist ebenfalls notwendig, um sicherzustellen, dass die Teilnehmenden die Umfrage ohne Schwierigkeiten durchführen können. Dies minimiert das Risiko von Abbrüchen und technischen Problemen und trägt zur Qualität und Vollständigkeit der erhobenen Daten bei.

Die Zustimmung zur Verarbeitung ihrer Daten ist ein essenzielles Kriterium, um die ethischen und rechtlichen Standards der Forschung einzuhalten. Die Einwilligung stellt sicher, dass die Teilnehmenden über die Verwendung ihrer Daten informiert sind und dieser zustimmen. Dies fördert das Vertrauen der Teilnehmenden und schützt ihre Rechte und Privatsphäre.

### 3.2.3 Gewählte Methoden

Die gewählte Methode für die Onlineumfrage ist die Verwendung von Skalen. Dabei werden verschiedene Skalenniveaus angewendet, um unterschiedliche Arten von Daten zu erfassen. In unserer Umfrage wird das nominale Skalenniveau für das Geschlecht der Teilnehmenden verwendet, wobei die Kategorien "Männlich" und "Weiblich" erfasst werden.

In unserer Umfrage werden der höchste allgemeinbildenden Schulabschluss und der höchste berufliche Abschluss auf ordinaler Basis erfasst, da sie eine Reihenfolge haben, aber keine genauen Abstände zwischen den Abschlüssen angegeben sind. Für den schulischen Abschluss stehen folgende Optionen zur Auswahl: "(noch) keinen Abschluss", "Hauptschulabschluss", "Realschulabschluss", "Abitur". Für den beruflichen Abschluss stehen folgende Optionen zur Auswahl: "(noch) keinen Abschluss", "Lehre/Ausbildung", "Fachschule", "Universität/Hochschule". 

Im Pre-test-Fragebogen und in beiden Post-test Fragebögen erfolgt die Abfrage mithilfe eines metrischen Skalenniveaus und einer sechsstufigen Likert-Skala. Die Teilnehmenden werden gebeten, ihre Zustimmung zu Aussagen auf einer Skala von "Stimmt gar nicht" über "Stimmt weitgehend nicht" und "Stimmt eher nicht" bis "Stimmt eher", "Stimmt weitgehend" und schließlich "Stimmt völlig" einzuschätzen. Die Likert-Skala ermöglicht eine differenzierte Bewertung, indem sie den Grad der Übereinstimmung oder Ablehnung mit den Aussagen bestimmt.

### 3.2.4 Analysemethode

Für unsere Onlineumfragen haben wir uns auf verschiedene Variablen fokussiert. Eine von diesen waren in dem Pre-test Fragebogen die soziodemographische Daten, wie z.B. Alter, Geschlecht und Bildungsgrad. Ebenfalls gehören dazu Daten zu der Persönlichkeit der Teilnehmenden, deren Einstellung zu Technik, Nutzungsgewohnheiten auf Social Media und deren Vorerfahrung mit KI.
Variablen für die System-Evaluation sind Präzision, die korrekten Entscheidungen und die Anzahl der Interaktionen die die 
ProbandInnen mit der KI hatten. Hier dienen diese Daten dazu, die ganze Interaktionsphase der ProbandInnen auswerten zu können.
Zuletzt kommen wir zu den Variablen des Post-test Fragebogen. Dort haben wir Usability, User Experience, subjektives Bewusstsein für die Informationsverarbeitung und Vertrauen in das System. Dies sind Daten zu der Bewertung der Anwendung.

Nach der Auswertung der Onlineumfragen werden quantitative Analysemethoden verwendet, darunter statistische Verfahren wie t-Test und die Pearson Korrelation. Diese Methoden dienen der Untersuchung von der ausgewählten Variablen Alter, Präzision und dem Human Computer Trust,um fundierte Erkenntnisse aus den Umfragedaten zu gewinnen. Der t-Test stellt fest, ob es einen signifikanten Unterschied zwischen den Mittelwerten von zwei Gruppen gibt. Dabei wollen wir untersuchen, ob es einen Unterschied in der Präsizion der ProbandInnen im Umgang mit unterschiedlichen KI-Tools in Hinblick auf das Alter gibt. Die Pearson Korrelation hingegen misst den Zusammenhang zwischen zwei Variablen und zeigt, in welchem Ausmaß sich Veränderungen einer Variable auf die andere Variable auswirkt. Dabei wollen wir wiederum untersuchen, inwiefern zwischen dem Alter und sowohl dem Vertrauen gegenüber den technischen Systemen als auch der Usability einen Zusammenhang besteht.  


# 4 Ergebnisse

## 4.1 Qualitative Ergebnisse

Aus der thematischen Analyse der Transkripte ergeben sich folgende Themen, die relevant für unsere Forschungsfrage sind: Misinformationen, Eigenschaften, Grenzen, Verantwortung und Transparenz.

| Name                              | Definition                                                                                    | Beleg                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
|-----------|-----------|--------------------------------------------------|
| Misinformationen auf Social Media | Notwendigkeit eines KI-Tools, das Informationen im Internet beurteilt und dessen Nützlichkeit | „Ehm, gerade auf Seiten wie Instagram und Tiktok, wo jeder posten kann was er will, muss man vorsichtig sein und darf nicht alles glauben, was einem präsentiert wird, da viele mit oder ohne Absicht andere beeinflussen, indem sie ihre Meinung verbreiten, weil diese von vielen sofort als Wahrheit angenommen wird.“ (A2_5, Zeile 45-49) „Ein ausreichend trainiertes KI System kann natürlich dabei helfen, schnell und ohne menschliches Eingreifen Misinformationen zu spotten und als solche zu flaggen, was es natürlich auch dem endgültigen User einfacher macht, Desinformation von tatsächlichen Fakten zu unterscheiden.“ (A2_4, Zeile 67-71) |
| Eigenschaften des KI-Tools        | Anforderungen an das KI-Tool, damit es zufriedenstellend und zielführend benutzbar ist        | „Es muss natürlich korrekt sein, also es muss ja schon auf jeden Fall richtig funktionieren.“ (A2_3, Zeile 45-46) „Okay, also ich sprach ja von einem Label und ich stelle mir da so einen Popup-Button vor, dass man da unten in der Mitte vom Screen zum Beispiel sieht man einen Popup-Button, da steht ‚Hierbei handelt es sich wahrscheinlich um Misinformation‘, dann klicken wir da drauf und wunderbar wäre es natürlich, wenn thematisch das aufgegriffen wird, wobei es sich um Misinformation handle und das versucht wird mit Fakten zu unterstützen.“ (A2_1, Zeile 104-110)                                                                     |
| Grenzen und Sorgen                | Grad, bis zu dem so ein System wirklich helfen und funktionieren kann                         | Es kam die Frage auf, ob die Kennzeichnung von Fake News tatsächlich dabei helfen würde, Bewusstsein zu schaffen oder ob die Fronten doch nur verhärtet würden. (vgl. A2_3, Zeile 142-145) „Und deshalb denke ich, dass noch viel daran gearbeitet werden muss, dass so was halt wirklich ernst genommen werden kann, weil KI halt noch nicht alles versteht und deshalb auch oft falsche Antworten liefert.“ (A2_2, Zeile 95-98)                                                                                                                                                                                                                            |
| Verantwortung für das KI-Tool     | Partie, die sich um Durchführung kümmert                                                      | „Irgendein Medium, dass keinen Vorteil hat, wenn Misinfromationen verbreitet werden, also neutral dem gegenübersteht.“ (A2_5, Zeile 97-98) „Ich denke die Verantwortung hat a uf jeden Fall die Social Media Seite.“ (A2_4, Zeile 150-151)                                                                                                                                                                                                                                                                                                                                                                                                                   |
| Transparenz des KI-Tools          | Beurteilungen des KI-Tools nachvollziehen können                                              | „Bei einem transparenten KI-Tool ist es wichtig, welche Daten verwendet werden, um das neutrale Netz zu trainieren und welche Quellen die KI als seriöse Quellen wertet.“ (A2_5, Zeile 105-107) „Ich finde es sollte Optionen geben, vielleicht könnte es einfach die Informationen sozusagen liefern und dann auch noch Optionen geben, dass man sozusagen den Gedankengang, also auch wenn KIs keinen Gedankengang haben, aber den Gedankengang dahinter noch mal, um den nachvollziehen zu können.“ (A2_3, Zeile 104-108)                                                                                                                                 |

Bei dem Thema „Misinformationen auf Social Media“ geht es darum, ob die Befragten ein KI-Tool dieser Art überhaupt als notwendig erachten. Alle Befragten haben angegeben, schon mal in Kontakt mit Misinformationen geraten zu sein. Außerdem wäre so ein System laut ihnen hilfreich und könne bis zu einem gewissen Grad definitiv dabei helfen, das Problem von Verbreitung von Misinformationen anzugehen. Wie man das System gestalten sollte, dass es den Anforderungen der Nutzenden entspricht, wird mit dem Thema „Eigenschaften des KI-Tools“ beschrieben. Höchste Priorität hatte bei den Befragten die Zuverlässigkeit des Systems. Es muss neutrale, faktenbasierte Entscheidungen treffen können und mit seriösen Quellen arbeiten. Am wichtigsten sei es, dass das System keine richtigen Informationen als falsch markiert und dass es sowohl Bild, Video, Audio und Text prüft, um ein bestmögliches Ergebnis zu liefern.

Wenn es um die direkte Nutzung geht, hatten mehrere Befragte die Vorstellung, dass die entsprechenden Posts mit einer Art Icon versehen werden, sodass man weiß, dass dieser Post Misinformationen enthält. Klickt man auf das Icon, wäre es optimal, wenn man noch mehr Informationen zu dem Thema bekommt oder die Option hat, sich selbst noch weiter zu informieren. Dieses Icon soll auch immer zu sehen sein und nicht erst auf Anfrage. Außerdem soll man die KI-Response melden können, im Falle einer falschen Markierung, aber mehr Interaktion muss mit dem System nicht möglich sein. Eine andere Idee für so ein System ist, dass man selbst Informationen in das System gibt und diese von der KI prüfen lässt und nicht, dass die KI automatisch immer alle Posts prüft.

Es wurden auch einige kritische Gedanken geäußert, die im Thema „Grenzen und Sorgen“ festgehalten sind. Zum einen wurde hinterfragt, ob eine KI subjektive Meinungen, Satire und Sarkasmus erkennen und beurteilen kann. Außerdem wurde mehrfach geäußert, dass die KI auf jeden Fall „neutral“, „unparteiisch“ oder „unbiased“ entscheiden müsse und ob es generell überhaupt möglich sei, eine KI mit solchen Anforderungen zu entwickeln.

Zum Thema „Verantwortung für das KI-Tool“ wäre die optimale Lösung, dass es eine dritte, unabhängige Partei gäbe, die keinen Nutzen von Verbreitung oder Verbergung von Informationen hat. Da dies aber unrealistisch erscheint, läge die Verantwortung wohl bei den Social Media Seiten, wobei auch der Gedanke geäußert wurde, dass es Richtlinien vom Staat geben soll, an die sich die Social Media Seiten halten müssen.

Als letztes geht es noch um das Thema „Transparenz des KI-Tools“. Man soll auf jeden Fall die Entscheidungen bzw. Beurteilungen der KI einsehen und nachvollziehen können und die Quellen, auf die sich die KI bezieht, überprüfen können. Außerdem seien Quelloffenheit des Codes und Transparenz im Datensatz, mit der die KI trainiert wird, wichtig.

## 4.2 Quantitative Ergebnisse

### 4.2.1 Stichprobe

Insgesamt haben 125 Personen an der Online-Studie teilgenommen. Die dabei für die Analyse zu berücksichtigenden Daten beinhalten die von 119 Teilnehmenden (*n =* 119). Zu den Personen, die herausgefiltert wurden, gehören eine Person, welche unter 18 Jahren ist und deswegen nicht berücksichtigt werden kann. Zudem fünf weitere Datensätze, die einer Testgruppe angehören.

Abgesehen davon haben die Teilnehmenden ein Durchschnittsalter von 26.7 Jahren (*M =* 26.7), wobei die Standardabweichung einen Wert von (*SD =* 11) hat. Auch, liegt das niedrigste Alter bei 18 Jahren (*n =* 5) und das höchste Alter bei 59 (*n =* 1).

Die Geschlechterverteilung der Teilnehmenden sieht folgendermaßen aus: 44.5 % der Teilnehmenden sind weiblich, 53.8 % sind männlich und 1.7 % gaben ein nicht binäres Geschlecht an.

Weitere für uns interessante soziodemografische Daten sind der höchste allgemeinbildende Schulabschluss und der höchste berufliche Abschluss. Mit 92.4 % hat die große Mehrheit der Teilnehmenden das Abitur, eine allgemeine oder fachgebundene Hochschulreife, einen erweiterten Oberschulabschluss oder eine Fachhochschulreife bzw. einen Abschluss der Fachoberschule. 5.9 % gaben an, die Realschule oder die Polytechnische Oberschule besucht zu haben bzw. die Mittlere Reife oder einen Mittleren Schulabschluss zu haben. Jeweils 0.8 % haben die Haupt- oder Volksschule besucht oder den Abschluss nach höchstens sieben Schuljahren gemacht.

Des Weiteren haben 55.5 % der Teilnehmenden (noch) keinen beruflichen Abschluss. 7.6 % haben dafür aber eine Lehre absolviert und 6.7 % eine Ausbildung. Die Fachschule haben 0.8 % der Teilnehmenden besucht und 5 % die Fachhochschule oder Ingenieurschule. Zuletzt gaben 24.4 % an, an einer Universität oder einer Hochschule den Abschluss gemacht zu haben.

Des Weiteren haben auch die Daten zur Nutzung sozialer Medien unter den Probanden eine Relevanz für unsere Forschung. Dabei nutzen 88.2 % der Teilnehmenden täglich soziale Medien, wie WhatsApp, Instagram und Facebook. 10.1 % nutzen sie mehrmals pro Woche und 0.8 % mehrmals im Monat. Ebenfalls gaben 0.8 % an, sie nie zu benutzen.

### 4.2.1 Deskriptive Statistik

Wir betrachten in unserer Analyse der Daten die ATI-Skala, die HCT-Skala und die SUS-Skala. Unsere Daten sind zusammengefasst in @tbl-skalen.

Grundsätzlich liegt die Standardabweichung aller Skalen zwischen den Bereichen 1.1 und 0.6. Wir haben somit kleinere Standardabweichungen, die darauf hinweisen, dass die Ergebnisse der Probanden sehr nah an ihren Mittelwerten liegen und daher eine hohe Konsistenz in ihrer Bedeutung vorliegt.

Der Alpha-Wert ist weiterhin bei allen Skalen hoch, sprich die Alpha-Werte liegen im Bereich zwischen 0 und 1. Daraus folgt, dass wir eine hohe interne Konsistenz der Messungen vorliegen haben.

Der Median weist in allen Skalen nur minimale Abstände zum durchschnittlichen Wert vor. Die Daten sind somit ungefähr symmetrisch um den Mittelwert verteilt. Es befinden sich daher keine Ausreißer oder extremen Werte, die den Durchschnitt stark verändern im Datensatz.

Die 9-Item-Skala zur Affinität für Technologie-Interaktion (ATI) misst die Neigung einer Person, sich aktiv mit intensiver Technologie-Interaktion zu beschäftigen oder diese zu meiden, und wird als wichtige persönliche Ressource für den erfolgreichen Umgang mit Technologie betrachtet. Bei unserer Studie liegt die durchschnittliche Technikaffinität der Teilnehmenden bei (*M =* 3.6, *SD =* 1.1). Die ATI-Skala hat einen möglichen Maximalwert von 6. Die Probanden besitzen dementsprechend weder eine besonders hohe, noch eine besonders niedrige Tendenz zur Technikaffinität.

Um herauszufinden, wie sehr eine Person einem Computer oder einem System vertraut, wird die HCT-Skala (engl. Human Computer Trust) benutzt. Dies wird anhand der Indikatoren Kompetenz, wahrgenommene Zuverlässigkeit und der wahrgenommenen Verständlichkeit abgeleitet. Der Score wurde für die 2 unterschiedlichen Systeme erfasst, wobei die Systeme den Probanden in jeweils zufälliger Reihenfolge gezeigt wurden. Die Evaluierende-AI hat dabei ein durchschnittliches Vertrauen von (*M =* 3.91, *SD =* 0.93) und Recommender-AI ein durchschnittliches Vertrauen, welches bei (*M =* 4.08, *SD =* 0.96) liegt. Die HCT-Skala hat einen möglichen Maximalwert von 6. Insgesamt lässt sich daraus folgern, dass die Probanden beiden Systemen  gegenüber ein tendenziell höheres Vertrauen aufweisen, es aber leichte Abweichungen gibt, welche vermutlich auf die Zufälligkeit der Zuordnung und der unterschiedlichen Einschätzungen der beiden KI-Systeme zurückzuführen sind. Insgesamt ist das durchschnittliche Vertrauen in die Recommender-AI höher als das in die Evaluierende-AI.

Mithilfe der SUS-Skala kann man ermitteln, wie gebrauchstauglich ein System ist. Die Gebrauchstauglichkeit der Evaluierenden-AI wurde durch die Teilnehmenden durchschnittlich mit (*M =* 3.98, *SD =* 0.66) bewertet. Die Recommender-AI wurde mit (*M =* 3.86 und *SD =* 0.57) bewertet. Im Allgemeinen lässt sich daraus erkennen, dass die Probanden mit der Gebrauchstauglichkeit der KI-Systeme zufrieden sind, der höchstmögliche Wert von 5 lässt aber darauf schließen, dass es Raum für Verbesserung gibt. Im Vergleich hat die Evaluierende-AI etwas besser abgeschnitten als die Recommender-AI. Dieser Unterschied liegt allerdings nur bei 0.12, ist also relativ gering.

```{r}
#| echo: false
#| message: false
#| warning: false


library(ggplot2)
library(dplyr)
library(tidyr)
library(scales)
library(psych)
library(kableExtra)
library(knitr)

ergebnissurvey <- read.csv("/Users/vanessa/Documents/UNI/Semester II/Statisktik und Nutzerforschung/2024-06-18/surveydata.csv")

ergebnisapp <- read.csv("/Users/vanessa/Documents/UNI/Semester II/Statisktik und Nutzerforschung/2024-06-18/appdata.csv")

#Erstes Filtern nach dem Alter 
ergebnissurvey <- ergebnissurvey %>%
  filter(age >= 18 & age < 120 & groupId != "42")

#Teil 2 Stichprobe
# 2.1 Geschlechterverteilung 

n <- nrow(ergebnissurvey)



gender_count <- ergebnissurvey %>%
  group_by(gender) %>%
  summarise(Frequency = n())

pct_female = gender_count %>% 
  filter(gender == 2) %>% 
  summarise(Weiblich = (Frequency / n )*100)
pct_male = gender_count %>% 
  filter(gender == 1) %>% 
  summarise(Männlich = (Frequency / n )*100)
pct_other = gender_count %>% 
  filter(gender == "-oth-") %>% 
  summarise(Andere = (Frequency / n )*100)



#---------------------------------------------------------------
#2.2 Bildungsabschluss
edugeneral_count <- ergebnissurvey %>%
  group_by(edugeneral) %>%
  summarise(Frequency = n())

if(nrow(filter(edugeneral_count, edugeneral == "1")) > 0) {
  pct_edugeneral1 = edugeneral_count %>% 
    filter(edugeneral == "1") %>% 
    summarise(Percentage = (Frequency / sum(Frequency)) * 100)
} else {
  pct_edugeneral1 = data.frame(pct_edugeneral1 = 0)
}
pct_edugeneral2 = edugeneral_count %>% 
  filter(edugeneral == "2") %>% 
  summarise(Percentage = (Frequency/n)*100)
pct_edugeneral3 = edugeneral_count %>% 
  filter(edugeneral == "3") %>% 
  summarise(Percentage = (Frequency/n)*100)
pct_edugeneral4 = edugeneral_count %>% 
  filter(edugeneral == "4") %>% 
  summarise(Percentage = (Frequency/n)*100)
pct_edugeneral5 = edugeneral_count %>% 
  filter(edugeneral == "5") %>% 
  summarise(Percentage = (Frequency/n)*100)

#---------------------------------------------------------------
#2.3 Arbeitsabschluss
eduvocational_count <- ergebnissurvey %>%
  group_by(eduvocational) %>%
  summarise(Frequency = n())

pct_eduvocational1 = eduvocational_count %>%
  filter(eduvocational == "1") %>%
  summarise(Percentage = (Frequency/n)*100)
pct_eduvocational2 = eduvocational_count %>%
  filter(eduvocational == "2") %>%
  summarise(Percentage = (Frequency/n)*100)
pct_eduvocational3 = eduvocational_count %>%
  filter(eduvocational == "3") %>%
  summarise(Percentage = (Frequency/n)*100)
pct_eduvocational4 = eduvocational_count %>%
  filter(eduvocational == "4") %>%
  summarise(Percentage = (Frequency/n)*100)
pct_eduvocational5 = eduvocational_count %>%
  filter(eduvocational == "5") %>%
  summarise(Percentage = (Frequency/n)*100)
pct_eduvocational6 = eduvocational_count %>%
  filter(eduvocational == "6") %>%
  summarise(Percentage = (Frequency/n)*100)

#---------------------------------------------------------------
#2.4 Social Media Nutzung
smfrequency_count <- ergebnissurvey %>%
  group_by(smfrequency) %>%
  summarise(Frequency = n())

smfrequency1 = smfrequency_count %>%
  filter(smfrequency == "1") %>%
  summarise(Percentage = (Frequency/n)*100)

smfrequency2 = smfrequency_count %>%
  filter(smfrequency == "2") %>%
  summarise(Percentage = (Frequency/n)*100)

smfrequency3 = smfrequency_count %>%
  filter(smfrequency == "3") %>%
  summarise(Percentage = (Frequency/n)*100)

smfrequency4 = smfrequency_count %>%
  filter(smfrequency == "4") %>%
  summarise(Percentage = (Frequency/n)*100)
smfrequency5 = smfrequency_count %>%
  filter(smfrequency == "5") %>%
  summarise(Percentage = (Frequency/n)*100)

  
#---------------------------------------------------------------
#2.4 Alter

stichprobenbeschreibung <- ergebnissurvey %>% summarise(n = nrow(ergebnissurvey), mean_age = mean(ergebnissurvey$age, na.rm = TRUE))

#stichprobenbeschreibung

#sd_age <- round(sd(ergebnissurvey$age),2)
#meann <- round(mean(ergebnissurvey$age),2)
#mediann <- round(median(ergebnissurvey$age),2)
#maxn <- round(max(ergebnissurvey$age),2)
#minn <- round(min(ergebnissurvey$age),2)

#tabelle_scorez <- rbind(meann, mediann, maxn,minn,sd_age )
#row.names(tabelle_scorez) <- c("Mean", "Median", "Max", "Min","Sd" )
#knitr::kable(tabelle_scorez, caption = "Altersübersicht")


                                                                                                    
#---------------------------------------------------------------

#Teil 3 
#Zusammenfügen von ergebnisapp und ergebnissurvey 

ergebnisapp <- ergebnisapp %>% group_by(user_id) %>%
    mutate(first_variant = first(variant))

ergebnisapp <- ergebnisapp %>% group_by(user_id) %>%
  mutate(correct_eval = ifelse(user_decision == correct_decision, 1, 0))

appdatasummarize <- ergebnisapp %>% group_by(user_id, variant) %>%
  summarize(mean_interactions = mean(number_of_interactions, na.rm = TRUE),
            precision = mean(correct_eval, na.rm = TRUE),
            first_variant = first(first_variant)) %>%
  pivot_wider(names_from = variant, values_from = c(mean_interactions, precision))


ergebnissurvey <- rename(ergebnissurvey, user_id = userId)



ergebnissurvey <- ergebnissurvey %>% left_join(appdatasummarize, by = "user_id", relationship = "many-to-many")

```

```{r}
#| echo: false
#| message: false
#| label: tbl-skalen
#| tbl-cap: "Deskriptive Statistik für ATI, HCT und SUS"
#| tbl-cap-location: top
#| warning: false


deskriptive_statistik <- function(data, scale_name) {

  filtered_data <- data %>% filter(!is.na(data[[scale_name]]))
  
  n <- nrow(filtered_data)  
    alpha <- round(psych::alpha(filtered_data %>% select(any_of(keys[[scale_name]])), check.keys = TRUE)$total$raw_alpha, 2)
  mean_val <- round(mean(filtered_data[[scale_name]], na.rm = TRUE),2)
  median_val <- round(median(filtered_data[[scale_name]], na.rm = TRUE),2)
  min_val <- round(min(filtered_data[[scale_name]], na.rm = TRUE),2)
  max_val <- round(max(filtered_data[[scale_name]], na.rm = TRUE),2)
  sd_val <- round(sd(filtered_data[[scale_name]], na.rm = TRUE),2)
  return(data.frame(n = n, alpha = alpha, mean = mean_val, median = median_val, min = min_val, max = max_val, sd = sd_val))
}

keys_ATI <- list(ATI = c("ATI.1.", "ATI.2.","-ATI.3.","ATI.4.","ATI.5.","-ATI.6.","ATI.7.","-ATI.8.","ATI.9."))
scored <- psych::scoreItems(keys_ATI, ergebnissurvey)
ergebnissurvey <- ergebnissurvey %>% cbind(scored$scores)

keys_HCT1 <- list(HCT1T = c("HCT1T.01.","HCT1T.02.","HCT1T.03.","HCT1T.04.","HCT1T.05." ))
scored <- psych::scoreItems(keys_HCT1, ergebnissurvey)
ergebnissurvey <- ergebnissurvey %>% cbind(scored$scores)

keys_HCT2 <- list(HCT2T = c("HCT2T.01.","HCT2T.02.","HCT2T.03.","HCT2T.04.","HCT2T.05." ))
scored <- psych::scoreItems(keys_HCT2, ergebnissurvey)
ergebnissurvey <- ergebnissurvey %>% cbind(scored$scores)


keys_SUS <- list(SUS = c("SUS.1.","-SUS.2.", "SUS.3.", "-SUS.4.", "SUS.5.", "-SUS.6.", "SUS.7.", "-SUS.8.", "SUS.9.", "-SUS.10."))
scored <- psych::scoreItems(keys_SUS, ergebnissurvey)
ergebnissurvey <- ergebnissurvey %>% cbind(scored$scores)



# Zuordnen der SIPA 1 und 2 zu den jeweiligen KI Tools
ergebnissurvey <- ergebnissurvey  %>%
  mutate(HCT_E = ifelse(first_variant == 'eva-ai', HCT1T, HCT2T),
         HCT_R = ifelse(first_variant == 'rd-ai', HCT1T, HCT2T))

# SUS-Werte basierend auf der zuerst gesehenen Anwendung zuweisen
ergebnissurvey <- ergebnissurvey %>%
  mutate(SUS_E = ifelse(first_variant == 'rd-ai', SUS, NA),
         SUS_R = ifelse(first_variant == 'eva-ai', SUS, NA))

# Schlüssel für Cronbachs Alpha
keys <- list(
  ATI = c("ATI.1.", "ATI.2.", "-ATI.3.", "ATI.4.", "ATI.5.", "-ATI.6.", "ATI.7.", "-ATI.8.", "ATI.9."),
  HCT_E = c("HCT1T.01.","HCT1T.02.","HCT1T.03.","HCT1T.04.","HCT1T.05."),
  HCT_R = c("HCT2T.01.","HCT2T.02.","HCT2T.03.","HCT2T.04.","HCT2T.05."),
   SUS_E = c("SUS.1.", "-SUS.2.", "SUS.3.", "-SUS.4.", "SUS.5.", "-SUS.6.", "SUS.7.", "-SUS.8.", "SUS.9.", "-SUS.10."),
  SUS_R = c("SUS.1.", "-SUS.2.", "SUS.3.", "-SUS.4.", "SUS.5.", "-SUS.6.", "SUS.7.", "-SUS.8.", "SUS.9.", "-SUS.10."))

# Berechnung der deskriptiven Statistik für die verschiedenen Skalen
ati_werte <- deskriptive_statistik(ergebnissurvey, "ATI")
hct_E_werte <- deskriptive_statistik(ergebnissurvey, "HCT_E")
hct_R_werte <- deskriptive_statistik(ergebnissurvey, "HCT_R")
sus_E_werte <- deskriptive_statistik(ergebnissurvey, "SUS_E")
sus_R_werte <- deskriptive_statistik(ergebnissurvey, "SUS_R")



tabelle_scores <- rbind(ati_werte, hct_E_werte, hct_R_werte,sus_E_werte,sus_R_werte )
row.names(tabelle_scores) <- c("ATI", "HCT_E", "HCT_R", "SUS_E","SUS_R" )
knitr::kable(tabelle_scores, caption = "Diskriptive Statistik für ATI, HCT und SUS")

```

### 4.2.1 Inferenzstatistik



```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Zusammenhang zwischen dem Alter und dem gemessenen ATI-Score"
#| label: fig-alterati

# Pakete laden
library(ggplot2)
library(dplyr)

ati <- read.csv("/Users/vanessa/Documents/UNI/Semester II/Statisktik und Nutzerforschung/2024-06-18/surveydata.csv", header = TRUE ,)

ati_columns <- grep("ATI", names(ati), value = TRUE)
ati <- ati %>%
  rowwise() %>%
  mutate(ATI_mean = mean(c_across(all_of(ati_columns)), na.rm = TRUE)) %>%
  ungroup()

mean_age <- mean(ati$age)
mean_ati_young <- mean(ati[ati$age < mean_age,"ATI_mean"])

mean_ati_old <- mean(ati[ati$age >= mean_age, "ATI_mean"]) 

cor5 <- cor.test(ergebnissurvey$age, ergebnissurvey$ATI)
#cor5

ageati <- ggplot(ergebnissurvey, aes(x = ergebnissurvey$age , y = ergebnissurvey$ATI)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, color = "royalblue") +
  labs(title = "Korrelation zwischen Alter und dem ATI-Score",
       x = "Alter",
       y = "ATI-Score")

#print(ageati)

```

#### 4.2.1.1 Durchführung des t-tests

Desweiteren wollten untersuchen, ob es bei der Präzision der richtigen Entscheidungen altersbezogene signifikante Unterschiede gibt. Um die Unterschiede bezüglich des Alters zu vergleichen, haben wir zuerst einen Median-Split des Alters durchgeführt und unsere Daten in zwei Gruppen aufgeteilt: Eine Gruppe die jünger und eine die älter als der Median ist. Nach dieser Aufteilung konnten wir den t-Test für beide KIs durchführen. Da wir zwei Variablen, Alter und Präzision, und somit zwei voneinander losgelöste Gruppen miteinander vergleichen wollen, haben wir einen unabhängigen t-test durchgeführt damit wir feststellen können wie signifikant der Unterschied der beiden Gruppen ist.\
Eine Visualisierung dieser Ergebnisse ist in @fig-ttest zu sehen.

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Ein Vergleich der Prototypen bezüglich der Präzision in Anbetracht des Alters"
#| label: fig-ttest

library(dplyr)
library(tidyr)
library(psych)
library(ggplot2)

#Inferenzenstatistik 
appdatasummarize <- appdatasummarize %>%
  left_join(ergebnissurvey %>% select(user_id, age), by = "user_id") %>% 
  filter(!is.na(age))

# precision_E: Anteil korrekt eingestufter Posts der evaluativen KI
precision_E <- ergebnissurvey %>%
  filter(first_variant == "eva-ai") %>%
  summarise(precision_E = mean(`precision_eva-ai`))

# mean_interactions_E: mittlere Anzahl an Interaktionen der evaluativen KI
mean_interactions_E <- ergebnissurvey %>%
  filter(first_variant == "eva-ai") %>%
  summarise(mean_interactions_E = mean(`mean_interactions_eva-ai`))

# precision_R: Anteil korrekt eingestufter Posts der Recommender KI
precision_R <- ergebnissurvey %>%
  filter(first_variant == "rd-ai") %>%
  summarise(precision_R = mean(`precision_rd-ai`))

#mean_interactions_R: mittlere Anzahl an Interaktionen der Recommender KI
mean_interactions_R <- ergebnissurvey %>%
  filter(first_variant == "rd-ai") %>%
  summarise(mean_interactions_R = mean(`mean_interactions_rd-ai`))






#t-test von den zwei Variablen in Anbetracht auf das Alter --> Vergleich von Alter und Präsision KI1 und KI2

median_age <- median(appdatasummarize$age, na.rm = TRUE)

#Bei appdatasummarize sind wir nur noch bei 119 Stichproben, da User ID nicht übereinstimmend
# Erstelle eine neue Spalte age_group basierend auf dem Median
appdatasummarize <- appdatasummarize %>%
  mutate(age_group = ifelse(age <= median_age, "Younger", "Older"))

# Erstelle zwei separate Tabellen basierend auf age_group
median_age_young <- appdatasummarize %>%
  filter(age_group == "Older")

median_age_old <- appdatasummarize %>%
  filter(age_group == "Younger")



# t-Test für die Präzision der evaluativen KI zwischen den Altersgruppen
t_test_precision_eva_ai <- t.test(median_age_young$`precision_eva-ai`, median_age_old$`precision_eva-ai`, alternative = "two.sided")

# t-Test für die Präzision der Recommender KI zwischen den Altersgruppen
t_test_precision_rd_ai <- t.test(median_age_young$`precision_rd-ai`, median_age_old$`precision_rd-ai`,  alternative = "two.sided")


# Ausgabe der Ergebnisse der t-Tests
#t_test_precision_eva_ai
#t_test_precision_rd_ai

# Berechnung der Mittelwerte und Standardfehler für RD-AI
mean_rd_old <- mean(median_age_old$`precision_rd-ai`)
mean_rd_young <- mean(median_age_young$`precision_rd-ai`)
se_rd_old <- sd(median_age_old$`precision_rd-ai`) / sqrt(length(median_age_old$`precision_rd-ai`))
se_rd_young <- sd(median_age_young$`precision_rd-ai`) / sqrt(length(median_age_young$`precision_rd-ai`))

# Erstellen des Datenrahmens für RD-AI
data_rd <- data.frame(
  group = c(rep("Älter", length(median_age_old$`precision_rd-ai`)), rep("Jünger", length(median_age_young$`precision_rd-ai`))),
  precision = c(median_age_old$`precision_rd-ai`, median_age_young$`precision_rd-ai`),
  type = rep("RD-AI", length(median_age_old$`precision_rd-ai`) + length(median_age_young$`precision_rd-ai`)),
  mean_precision = c(rep(mean_rd_old, length(median_age_old$`precision_rd-ai`)), rep(mean_rd_young, length(median_age_young$`precision_rd-ai`))),
  se_precision = c(rep(se_rd_old, length(median_age_old$`precision_rd-ai`)), rep(se_rd_young, length(median_age_young$`precision_rd-ai`)))
)

# Berechnung der Mittelwerte und Standardfehler für EVA-AI
mean_eva_old <- mean(median_age_old$`precision_eva-ai`)
mean_eva_young <- mean(median_age_young$`precision_eva-ai`)
se_eva_old <- sd(median_age_old$`precision_eva-ai`) / sqrt(length(median_age_old$`precision_eva-ai`))
se_eva_young <- sd(median_age_young$`precision_eva-ai`) / sqrt(length(median_age_young$`precision_eva-ai`))

# Erstellen des Datenrahmens für EVA-AI
data_eva <- data.frame(
  group = c(rep("Älter", length(median_age_old$`precision_eva-ai`)), rep("Jünger", length(median_age_young$`precision_eva-ai`))),
  precision = c(median_age_old$`precision_eva-ai`, median_age_young$`precision_eva-ai`),
  type = rep("EVA-AI", length(median_age_old$`precision_eva-ai`) + length(median_age_young$`precision_eva-ai`)),
  mean_precision = c(rep(mean_eva_old, length(median_age_old$`precision_eva-ai`)), rep(mean_eva_young, length(median_age_young$`precision_eva-ai`))),
  se_precision = c(rep(se_eva_old, length(median_age_old$`precision_eva-ai`)), rep(se_eva_young, length(median_age_young$`precision_eva-ai`))))

# Zusammenführen der Daten für den gesamten Plot
data_combined <- rbind(data_rd, data_eva)

# Boxplot erstellen
plot <- ggplot(data_combined, aes(x = group, y = precision, fill = group)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.5) +
  facet_wrap(~ type, scales = "free_y", ncol = 1) +
  labs(title = "Präzision der AI-Systeme in Abhängigkeit des Alters",
       x = "Gruppe",
       y = "Präzision") +
  scale_fill_manual(values = c("Älter" = "paleturquoise3", "Jünger" = "olivedrab3")) +
  theme_minimal()

# Plot anzeigen
plot + 
  geom_point(data = data_combined, aes(x = group, y = mean_precision), color = "tomato2", size = 3) +
  geom_errorbar(data = data_combined, aes(x = group, ymin = mean_precision - se_precision, ymax = mean_precision + se_precision), color = "tomato2", width = 0.2)

```

#### 4.2.1.2 Auswertung des t-tests

Bei der Evaluierenden KI (@fig-ttest) ergab der t-Test folgende Ergebnisse:

-   *t =* 0.92
-   *df =* 115.42
-   *p =* 0.36

Da der p-Wert größer als 0.05 ist, bedeutet dies, dass der Unterschied in den Mittelwerten der Präzision zwischen den jüngeren und älteren Gruppen nicht signifikant ist. Die Wahrscheinlichkeit, dass der beobachtete Unterschied zufällig ist, liegt bei etwa 36.17 %, was weit über der üblichen Schwelle von 5 % liegt. Da es keinen signifikanten Unterschied in der Präzision der beiden Altersgruppen bei der evaluierenden KI gibt, ist nicht anzunehmen, dass das Alter einen Einfluss auf die Präzision beim Treffen von Entscheidungen hat.

Bei der Recommender-KI (@fig-ttest) ergab der t-Test folgende Ergebnisse:

-   *t =* 1.42
-   *df =* 108.92
-   *p =* 0.16

Auch hier ist der p-Wert größer als 0.05, was bedeutet, dass der Unterschied in der Präzision zwischen den Altersgruppen nicht signifikant ist. Die Wahrscheinlichkeit, dass der beobachtete Unterschied zufällig ist, liegt bei etwa 15.89 %, was ebenfalls über der Schwelle von 5 % liegt. Daher ist auch bei dieser KI nicht anzunehmen, dass es einen signifikanten Einfluss des Alters auf die Präzision der Entscheidungen gibt.

Die t-Tests für beide KIs liefern also das gleiche Ergebnis, dass es keinen signifikanten Unterschied zwischen den beiden Altersgruppen bei der Präzision gibt. Beide Gruppen können also gleich gut beurteilen, ob es sich bei den präsentierten Informationen um die Wahrheit handelt oder nicht.

#### 4.2.1.3 Durchführung der Pearson-Korrelation in Hinblick auf Alter und HCT-Score

Da wir uns in unserer Forschung besonders auf den Umgang verschiedener Altersgruppen mit den Systemen fokussieren, schauen wir uns den Zusammenhang zwischen dem Alter und dem HCT-Score, also dem Human-Computer-Trust, genauer an. Um zu überprüfen, ob es hier tatsächlich einen relevanten Zusammenhang gibt, haben wir einen Pearson-Korrelationstest durchgeführt.

Dabei haben wir uns die Ergebnisse der “Perceived Technical Competence”, also der wahrgenommenen technischen Kompetenz des Systems, genauer angeschaut. 
Den Test haben wir sowohl für die Evaluierende-AI als auch für die Recommender-AI durchgeführt und auch diese in den @fig-cor1test (Korrelation zwischen dem Alter der Probanden und dem HCT-Score der Evaluierenden-AI) und @fig-cor2test (Korrelation zwischen dem Alter der Probanden und dem HCT-Score der Recommender-AI) visuell dargestellt.


#### 4.2.1.4 Auswertung der Pearson-Korrelation

Die Analyse der Recommender-AI ergab einen nicht signifikanten Zusammenhang mit einem t-Wert von -0.95  und einem p-Wert von 0.34 . Es gibt also keine signifikante Korrelation zwischen dem Alter der Nutzenden und dem Vertrauen in die Systeme (*p >* 0.05).

Der Test zur Evaluierenden-AI liefert einen signifikanten Zusammenhang, mit einem t-Wert von -3.56 und einem p-Wert von  0.00054. Hier korreliert das Alter der Probanden signifikant negativ mit ihrem HCT-Score. Der Korrelationskoeffizient in diesem Fall betrug -0.31, was darauf hinweist, dass ältere Probanden bei diesem KI-System niedrigere HCT-Scores aufwiesen. 

Bei der Recommender-AI konnten also beide Altersgruppen ein ähnliches Level an Vertrauen in das System aufbauen.Bei der Evaluierenden-AI zeigte sich wiederum, dass das Alter der Probanden einen signifikanten Einfluss auf ihren HCT-Score hat, wobei ältere Probanden im Durchschnitt niedrigere HCT-Scores erreichten. Während der durchschnittliche HCT-Score bei der jüngeren Hälfte der Befragten bei beiden KI-Systemen relativ ähnlich war (4.21 bei der Recommender-AI und 4.15 bei der Evaluierenden-AI), war der HCT-Score bei der älteren Hälfte insgesamt etwas niedriger, aber besonders bei der Evaluierenden-AI signifikant niedriger als bei der Recommender-AI (3.95 für die Recommender-AI und 3.66 für die Evaluierende-AI). 



```{r}
#| echo: false
#| message: false
#| warning: false

library(dplyr)
library(tidyr)
library(psych)
library(ggplot2)


# Berechnung der Mittelwerte für verschiedene Gruppen
mean_values <- ergebnissurvey %>%
  mutate(age_group = ifelse(age <= median_age, "Jünger", "Älter")) %>%
  group_by(age_group, first_variant) %>%
  summarise(mean_HCT_E = round(mean(HCT_E, na.rm = TRUE),3),
            mean_HCT_R = round(mean(HCT_R, na.rm = TRUE),3))

# Umwandlung der Ergebnisse in ein Datenframe-Format für die Tabelle
tabelle_scores <- mean_values %>%
  pivot_longer(cols = c(mean_HCT_E, mean_HCT_R), names_to = "score_type", values_to = "mean_score") %>%
  pivot_wider(names_from = age_group, values_from = mean_score)


# Erstellung der Tabelle mit knitr::kable
knitr::kable(tabelle_scores, caption = "Deskriptive Statistik für HCT E und HCT R")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Korrelation zwischen dem Alter der Probanden und dem HCT-Score der Evaluierenden AI"
#| label: fig-cor1test

library(dplyr)
library(tidyr)
library(psych)
library(ggplot2)


cor1 <- cor.test(ergebnissurvey$age, ergebnissurvey$HCT_E)
#cor1

ggplot(ergebnissurvey, aes(x = ergebnissurvey$age , y = ergebnissurvey$HCT_E)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE,color = "royalblue") +
  labs(title = "Korrelation zwischen Alter und HCT-Score der Eva-Ai",
       x = "Alter",
       y = "HCT-Score")

```

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Korrelation zwischen dem Alter der Probanden und dem HCT-Score der RD-AI"
#| label: fig-cor2test

cor2 <- cor.test(ergebnissurvey$age, ergebnissurvey$HCT_R)
#cor2

ggplot(ergebnissurvey, aes(x = ergebnissurvey$age , y = ergebnissurvey$HCT_R)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE,color = "royalblue") +
  labs(title = "Korrelation zwischen Alter und HCT-Score der RD-AI",
       x = "Alter",
       y = "HCT-Score")

```

#### 4.2.1.5 Durchführung der Pearson-Korrelation in Hinblick auf Alter und SUS-Score
Neben dem HCT-Score haben wir auch die SUS-Skala ausgewertet, um mögliche Unterschiede in der Einschätzung der Usability zwischen den Altersgruppen zu finden. Eine Visualisierung ist in @fig-cor3test zu sehen.

#### 4.2.1.6 Durchführung der Pearson-Korrelation in Hinblick auf Alter und SUS-Score
Der Korrelationstest zwischen Alter und SUS-Score ergab keine signifikanten Ergebnisse, da der p-Wert deutlich über der Schwelle von 0.05 liegt. (*t =*  0.66, *df =* 117, *p =* 0.51)
Die Usability der beiden KI-Systeme ist also über alle Altersgruppen hinweg konsistent.


```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Korrelation zwischen dem Alter der Probanden und dem SUS-Score"
#| label: fig-cor3test

library(dplyr)
library(tidyr)
library(psych)
library(ggplot2)


cor3 <- cor.test(ergebnissurvey$age, ergebnissurvey$SUS)
#cor3

ggplot(ergebnissurvey, aes(x = ergebnissurvey$age , y = ergebnissurvey$SUS)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE,color = "royalblue") +
  labs(title = "Korrelation zwischen Alter und SUS-Score",
       x = "Alter",
       y = "SUS-Score")

```

#### 4.2.1.6 Abschließende Zusammenfassung der Inferenzstatistik

In unserer inferenzstatistischen Analyse konnten wir herausstellen, dass ältere ProbandInnen im Durchschnitt niedrigere HCT-Scores erreichten. Da das Vertrauen in zumindest eines der Systeme bei älteren ProbandInnen niedriger ist, ließe sich vermuten, dass sich dies auch auf den Umgang und schließlich die Präzision der Einschätzung auswirkt. Hier konnten wir mit unserem t-Test allerdings keinen signifikanten Zusammenhang erkennen. 

Auch in den Ergebnissen der SUS-Skala ließ sich kein signifikanter Zusammenhang mit dem Alter finden. Aktuell scheinen also sowohl ältere als auch jüngere Probanden unabhängig vom Vertrauen in das System die gleichen Ergebnisse zu erzielen. 

Zusätzlich zu den altersbedingten Unterschieden, ließen sich auch Unterschiede zwischen den beiden KI-Systemen feststellen. So lag der durchschnittliche HCT-T-Score der Recommender-AI über dem der Evaluierenden-AI. Die Nutzenden haben also mehr Vertrauen in die technische Kompetenz der Recommender-AI, was sich jedoch nicht signifikant in der Präzision widerspiegelt.


# 5 Diskussion
Das Ziel unserer Studie war es herauszufinden, ob das Alter eines Menschen ein entscheidender Faktor bei der Konzipierung von KI-Systemen zur Detektion von Misinformationen ist und ob dies weiterführend mit der Technikaffinität oder dem Vertrauen gegenüber technischen Systemen zusammenhängt. 
Um diese Frage zu beantworten, haben wir zuerst Interviews und später eine Onlineumfrage durchgeführt und dabei versucht, Personen aus möglichst vielen Altersgruppen zu befragen. In dem Fragebogen wurden neben demographischen Daten zwei KI-Systeme vorgestellt, mit deren Hilfe die ProbandInnen einschätzen sollten, ob es sich bei den vorgelegten Informationen um Misinformation handelt. Uns lagen also die Daten zur Präzision der richtigen Einschätzung, sowie Scores wie ATI, HCT und SUS vor.
Für unsere Auswertung haben wir die Ergebnisse dann in zwei Gruppen geteilt: ProbandInnen, die älter bzw. jünger als der Median sind. Daraufhin konnten wir feststellen, dass es zwar einen kleinen, aber nicht signifikanten Unterschied in den ATI-Scores gibt und auch die Präzision sich nicht wesentlich zwischen den beiden Gruppen unterscheidet. Lediglich in den HCT-Scores gab es eine signifikante Korrelation.

In Bezug auf unsere Forschungsfrage lässt sich also sagen, dass ältere Menschen KI-Systemen  kritischer gegenüberstehen und diesen nicht so schnell Vertrauen schenken, wie jüngere Nutzer. Dieser Unterschied konnte vor allem bei der Evaluierenden-AI festgestellt werden, während das Vertrauen bei der Recommender-AI über alle Altersgruppen vergleichsweise gleich blieb. Älteren Menschen fällt es also schwieriger, der Evaluierenden-AI zu vertrauen. Allerdings wirkt sich dieses Missvertrauen nicht auf die Ergebnisse aus, die schlussendlich mit dieser KI erzielt wurden. Bei beiden KI-Systemen, gab es keinen signifikanten Unterschied in der Präzision zwischen den Altersklassen. Insofern scheint das Vertrauen in diese Systeme nicht zu beeinflussen, ob die Informationen am Ende richtig eingeschätzt werden.

## 5.1 Implikationen
Die Erkenntnisse dieser Studie liefern Hinweise darauf, dass ältere Menschen eher misstrauischer gegenüber neuen technischen Systemen, wie zum Beispiel gegenüber KI, eingestellt sind als jüngere Menschen. Dieses Phänomen lässt sich auch auf andere technische Bereiche wie zum Beispiel Online-Banking und andere digitale Dienstleistungen übertragen.
Überraschenderweise korreliert das Alter der Menschen jedoch nicht so stark mit der Präzision im Umgang mit KI-Systemen, wie vorher gedacht. Stärkeres Vertrauen in ein System ist also nicht gleichzusetzen mit besserem Umgang mit diesem System.
Wenn man ein System konzipiert, muss man darauf achten, alle Menschengruppen anzusprechen und zu inkludieren. Man muss also die jeweiligen Bedürfnisse und Fähigkeiten von den verschiedenen Altersgruppen richtig einschätzen, um deren Akzeptanz und Nutzung zu fördern. Zudem könnte man zusätzlich versuchen, das Vertrauen der älteren Menschen zu erhöhen, indem man sie mehr in Testphasen von den Systemen heranzieht oder auch versucht, sie mehr in diese Richtung zu bilden. Unterschiedliche Einstellungen gegenüber Themen, wie zum Beispiel Technologien können zu einer Schere zwischen den Generationen führen. Im Hinblick darauf ist es erstrebenswert, älteren Menschen einen leichteren Zugang zu ermöglichen. Menschen sind generell eher abgeneigt gegenüber Systemen, denen sie nicht vertrauen oder die sie nicht so gut verstehen und bedienen können. Daraus folgt dann auch, dass sie sich davor scheuen, sich damit intensiver auseinanderzusetzen. 
Auf den Ergebnissen basierend sollte der Fokus also darauf liegen, herauszufinden, wie das Vertrauen älterer Menschen in technische Systeme gestärkt werden kann. Mögliche Verbesserungsansätze könnten dabei die Transparenz, beziehungsweise die Nachvollziehbarkeit der Vorgehensweise und des Entscheidungsprozesses der KI-Systeme sein. Dies könnte das Vertrauen und somit auch die Akzeptanz dieser erhöhen. Dabei sollte besonders der Unterschied zwischen den beiden AI-Systemen analysiert werden, da wir hier bereits einen Unterschied feststellen konnten.

## 5.2 Limitationen
Unsere bisherige Umfrage hat an einer relativ kleinen Gruppe stattgefunden, in der insbesondere die Altersgruppen von 30 - 50 Jahren und Menschen über 60 Jahren nur sehr gering beteiligt waren, sodass eine vollständige Auswertung über alle Altersgruppen nicht möglich ist. Desweiteren haben wir für den t-test einen Median-Split durchgeführt, der aufgrund der ungleichen Altersverteiltung eine Trennung bei ca. 22 Jahren veranlasst hat, was somit wiederum keine wirklich repräsentative Spaltung des Altersbereichs von 18-60 Jahren herbeigeführt hat. So konnten wir bisher bereits eine erste Tendenz im Umgang mit KI-Systemen erlangen, allerdings noch keine detaillierte Analyse in kleineren Altersabschnitten durchführen. 
Kleinere Gruppen könnten auch zu klareren Ergebnissen bei der Präzision führen, da bei unserer Altersspanne die Ergebnisse sich gegenseitig ausgleichen können. 
Aus unseren Ergebnissen lässt sich bisher zwar ableiten, dass ältere Menschen der Recommender-AI mehr Vertrauen schenken als der Evaluierenden-AI, allerdings lässt sich nicht konkret spezifizieren, welche Elemente des Systems das Vertrauen weckt bzw. senkt. Um zukünftige Systeme zu entwickeln, wäre also eine detaillierte Analyse wichtig, um klare Eigenschaften der Systeme benennen zu können.


## 5.3 Zukünftige Arbeit
Für weitere Forschung wäre also eine Datenerhebung mit Probanden aus allen Altersgruppen sinnvoll, damit genauer analysiert werden kann, welche Altersgruppe welches Vertrauen in technische Systeme steckt. Weiterhin wäre interessant, ob es bei kleineren Gruppen möglicherweise doch Unterschiede in der Präzision gibt, die bei uns durch die großen Teilgruppen ausgeglichen wurden.
Weiterhin sollten die Gründe des geringen Vertrauens genauer betrachtet werden, um die KI-Systeme auch wirklich an die Bedürfnisse der Nutzenden anpassen zu können. Dabei sollte der Fokus insbesondere auf ältere Altersgruppen gelegt werden, um dafür zu sorgen, dass alle Altersgruppen die Systeme mit gleichem Vertrauen nutzen können.

# 6 Literaturverzeichnis

::: {#refs}
:::

# 7 Anhänge

## Anhang 1 - Rekrutierungstext

Hallo zusammen!

Falschinformationen sind weit verbreitet und jeder ist mit Ihnen tagtäglich konfrontiert. In unserer Fragenbogenstudie testest du ein KI Werkzeug (Künstliche Intelligenz), welches dir hilft irreführende Informationen im Internet zu erkennen. Die Studie dauert ca. 30 - 45 Minuten und kann einfach vom Laptop / Tablet / PC online durchgeführt werden. Medieninformatik- und Psychologie-Studierende der Universität Lübeck erhalten für die Teilnahme 0,5 VP Stunden.

Unsere Einschlusskriterien sind

-   Mindestens 18 Jahre alt

-   Gute Deutschkenntnisse

Wir freuen uns auf deine Teilnahme!

## Anhang 2 - Einwillingungserklärungen der Interviews

## Anhang 3 - Transkription der Interviews
{include file=""}
